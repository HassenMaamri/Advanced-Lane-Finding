{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import glob \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from IPython.display import HTML\n",
    "from moviepy.editor import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions definitions\n",
    "\n",
    "def read_images():\n",
    "    test_image_names = glob.glob('./test_images/*.jpg')\n",
    "    test_images = []\n",
    "    for test_image_name in test_image_names:\n",
    "        image = plt.imread(test_image_name)\n",
    "        test_images.append(image)\n",
    "    return test_images\n",
    "\n",
    "def undistort(image):\n",
    "    calibration = pickle.load( open(\"calibration.p\", \"rb\") )\n",
    "    mtx = calibration['mtx']\n",
    "    dist = calibration['dist']\n",
    "    undist = cv2.undistort(image,mtx,dist,None,mtx)\n",
    "    return undist\n",
    "\n",
    "def undistort_rect(image):\n",
    "    img_size = (image.shape[1], image.shape[0])\n",
    "    undistorted_drawn = cv2.rectangle(np.copy(image), pt1=(0,img_size[1]), pt2=(img_size[0],img_size[1]-100), color=(255,0,0), thickness=3)\n",
    "    return undistorted_drawn\n",
    "\n",
    "def abs_sobel_thresh(image, orient = 'x', sobel_kernel=9, thresh = (2.1,15)):\n",
    "    gray = cv2. cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    if orient == 'x':\n",
    "        sobel = cv2.Sobel(gray, cv2.CV_64F, 1, 0 ,ksize = sobel_kernel)\n",
    "    if orient =='y':\n",
    "        sobel = cv2.Sobel(gray, cv2.CV_64F, 0, 1 ,ksize = sobel_kernel)\n",
    "    \n",
    "    abs_sobel = np.absolute(sobel)\n",
    "    scaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "\n",
    "    abs_sobel_thresh = np.zeros_like(scaled_sobel)\n",
    "    abs_sobel_thresh[(scaled_sobel > thresh[0]) & (scaled_sobel < thresh[1])] = 1\n",
    "\n",
    "    return abs_sobel_thresh\n",
    "\n",
    "#Convert to grayscale, calculate magnitude, rescale and return binary output\n",
    "def mag_thresh(image, sobel_kernel=3, thresh=(1, 5)):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0 ,ksize = sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1 ,ksize = sobel_kernel)\n",
    "\n",
    "    gradient_magnitude = np.sqrt(sobelx**2 + sobely**2)\n",
    "    scaled_magnitude = np.uint8(255*gradient_magnitude/np.max(gradient_magnitude))\n",
    "\n",
    "    output = np.zeros_like(scaled_magnitude)\n",
    "    output[(scaled_magnitude > thresh[0]) & (scaled_magnitude < thresh[1])] = 1\n",
    "\n",
    "    return output\n",
    "\n",
    "#Convert to grayscale, calculate x and y gradients and apply threshold\n",
    "def dir_thresh(image, sobel_kernel=3, thresh=(0, np.pi/2)):\n",
    "    gray = cv2. cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0 ,ksize = sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1 ,ksize = sobel_kernel)\n",
    "\n",
    "    abs_sobelx = np.absolute(sobelx)\n",
    "    abs_sobely = np.absolute(sobely)\n",
    "\n",
    "    absgraddir = np.arctan2(sobely, sobelx)\n",
    "\n",
    "    output = np.zeros_like(absgraddir)\n",
    "    output[(absgraddir > thresh[0]) & (absgraddir < thresh[1])] = 1\n",
    "\n",
    "    return output\n",
    "\n",
    "def rgb_thresh(image, channel=\"r\", thresh=(0, 1)):\n",
    "    if channel==\"r\":\n",
    "        thrshld_channel = image[:,:,0]\n",
    "    if channel==\"g\":\n",
    "        thrshld_channel = image[:,:,1]\n",
    "    if channel==\"b\":\n",
    "        thrshld_channel = image[:,:,2]\n",
    "\n",
    "    rgb_thrshld = np.zeros_like(thrshld_channel)\n",
    "    rgb_thrshld[(thrshld_channel > thresh[0]) & (thrshld_channel < thresh[1])] = 1\n",
    "    return rgb_thrshld\n",
    "\n",
    "def hls_thresh(image, channel=\"h\", thresh=(0, 50)):\n",
    "    hls = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "\n",
    "    if channel==\"h\":\n",
    "        thrshld_channel = hls[:,:,0]\n",
    "    if channel==\"l\":\n",
    "        thrshld_channel = hls[:,:,1]\n",
    "    if channel==\"s\":\n",
    "        thrshld_channel = hls[:,:,2]\n",
    "\n",
    "    hls_threshold = np.zeros_like(thrshld_channel)\n",
    "    hls_threshold[(thrshld_channel > thresh[0]) & (thrshld_channel < thresh[1])] = 1\n",
    "    return hls_threshold\n",
    "\n",
    "def hsv_thresh(image, channel=\"h\", thresh=(0, 50)):\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "    if channel==\"h\":\n",
    "        thrshld_channel = hsv[:,:,0]\n",
    "    if channel==\"s\":\n",
    "        thrshld_channel = hsv[:,:,1]\n",
    "    if channel==\"v\":\n",
    "        thrshld_channel = hsv[:,:,2]\n",
    "\n",
    "    hsv_threshold = np.zeros_like(thrshld_channel)\n",
    "    hsv_threshold[(thrshld_channel > thresh[0]) & (thrshld_channel < thresh[1])] = 1\n",
    "    return hsv_threshold\n",
    "\n",
    "def YCrCb_thresh(image, channel=\"Y\", thresh=(0, 50)):\n",
    "    YCrCb = cv2.cvtColor(image, cv2.COLOR_RGB2YCrCb)\n",
    "\n",
    "    if channel==\"Y\":\n",
    "        thrshld_channel = YCrCb[:,:,0]\n",
    "    if channel==\"Cr\":\n",
    "        thrshld_channel = YCrCb[:,:,1]\n",
    "    if channel==\"Cb\":\n",
    "        thrshld_channel = YCrCb[:,:,2]\n",
    "\n",
    "    YCrCb_threshold = np.zeros_like(thrshld_channel)\n",
    "    YCrCb_threshold[(thrshld_channel > thresh[0]) & (thrshld_channel < thresh[1])] = 1\n",
    "    return YCrCb_threshold\n",
    "\n",
    "def combine_threshs(hls_thresh_1, abs_sobel_thresh_1):\n",
    "    combined = np.zeros_like(hls_thresh_1)\n",
    "    combined[hls_thresh_1 == 1] = 1\n",
    "    combined[abs_sobel_thresh_1 == 1] = 1\n",
    "    return combined\n",
    "\n",
    "def filter(image):\n",
    "    height, width = image.shape[0], image.shape[1]\n",
    "    bl = (width / 2 - 480, height - 30)\n",
    "    br = (width / 2 + 480, height - 30)\n",
    "    tl = (width / 2 - 60, height / 2 + 76)\n",
    "    tr = (width / 2 + 60, height / 2 + 76)\n",
    "\n",
    "    fit_left = np.polyfit((bl[0], tl[0]), (bl[1], tl[1]), 1)\n",
    "    fit_right = np.polyfit((br[0], tr[0]), (br[1], tr[1]), 1)\n",
    "    fit_bottom = np.polyfit((bl[0], br[0]), (bl[1], br[1]), 1)\n",
    "    fit_top = np.polyfit((tl[0], tr[0]), (tl[1], tr[1]), 1)\n",
    "\n",
    "    # Find the region inside the lines\n",
    "    x, y = np.meshgrid(np.arange(0, image.shape[1]), np.arange(0, image.shape[0]))\n",
    "    mask = (y > (x * fit_left[0] + fit_left[1])) & \\\n",
    "           (y > (x * fit_right[0] + fit_right[1])) & \\\n",
    "           (y > (x * fit_top[0] + fit_top[1])) & \\\n",
    "           (y < (x * fit_bottom[0] + fit_bottom[1]))\n",
    "    \n",
    "    image_window = np.copy(image)\n",
    "    image_window[mask == False] = 0\n",
    "\n",
    "    return image_window\n",
    "\n",
    "def transform_image(windowed_image, M, img_size):\n",
    "    return cv2.warpPerspective(windowed_image, M, img_size)\n",
    "\n",
    "def get_hist(img):\n",
    "    hist = np.sum(img[int(img.shape[0]//2):,:], axis=0)\n",
    "    #hist = np.sum(img[img.shape[0]/2:,:], axis=0)\n",
    "    return hist\n",
    "\n",
    "ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "\n",
    "def find_lanes(persp):\n",
    "    #create historgram for bottom half of persp\n",
    "    hist = np.sum(persp[int(persp.shape[0]/2):,:], axis=0) \n",
    "    #output image to draw on + visualize\n",
    "    out_img = np.dstack((persp, persp, persp))*255\n",
    "    #peaks of left + right halves if hist\t\n",
    "    midpoint = np.int(hist.shape[0]/2)\n",
    "    leftx_base = np.argmax(hist[:midpoint])\n",
    "    rightx_base = np.argmax(hist[midpoint:]) + midpoint\n",
    "    #number of sliding windows\n",
    "    nwindows = 9\n",
    "    #window height \n",
    "    window_height = np.int(persp.shape[0]/nwindows)\n",
    "\n",
    "    #x and y positions of all nonzero pizels in img\n",
    "    nonzero = persp.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "\n",
    "    #current positions to be updated\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "\n",
    "    #width of windows +/- margin\n",
    "    margin = 100\n",
    "    #min number of pixels to recenter window\n",
    "    minpix = 50\n",
    "\n",
    "    #empty lists to receive left and right lane pixel indices\n",
    "    left_lane_indices = []\n",
    "    right_lane_indices = []\n",
    "\n",
    "    #go through windows one by one\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = persp.shape[0] - (window+1)*window_height\n",
    "        win_y_high = persp.shape[0] - window*window_height\n",
    "        win_xleft_low = leftx_current - margin\n",
    "        win_xleft_high = leftx_current + margin\n",
    "        win_xright_low = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "        # Draw the windows on the visualization image\n",
    "        cv2.rectangle(out_img,(win_xleft_low,win_y_low),(win_xleft_high,win_y_high),(0,255,0), 2) \n",
    "        cv2.rectangle(out_img,(win_xright_low,win_y_low),(win_xright_high,win_y_high),(0,255,0), 2) \n",
    "        # Identify the nonzero pixels in x and y within the window\n",
    "        good_left_indices = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xleft_low) & (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        good_right_indices = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xright_low) & (nonzerox < win_xright_high)).nonzero()[0]\n",
    "        # Append these indices to the lists\n",
    "        left_lane_indices.append(good_left_indices)\n",
    "        right_lane_indices.append(good_right_indices)\n",
    "        # If you found > minpix pixels, recenter next window on their mean position\n",
    "        if len(good_left_indices) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_indices]))\n",
    "        if len(good_right_indices) > minpix:        \n",
    "            rightx_current = np.int(np.mean(nonzerox[good_right_indices]))\n",
    "\n",
    "    # Concatenate the arrays of indices\n",
    "    left_lane_indices = np.concatenate(left_lane_indices)\n",
    "    right_lane_indices = np.concatenate(right_lane_indices)\n",
    "\n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_indices]\n",
    "    lefty = nonzeroy[left_lane_indices] \n",
    "    rightx = nonzerox[right_lane_indices]\n",
    "    righty = nonzeroy[right_lane_indices] \n",
    "\n",
    "    # Fit a second order polynomial to each\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "\n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, persp.shape[0]-1, persp.shape[0] )\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "\n",
    "    out_img[nonzeroy[left_lane_indices], nonzerox[left_lane_indices]] = [255, 0, 0]\n",
    "    out_img[nonzeroy[right_lane_indices], nonzerox[right_lane_indices]] = [0, 0, 255]\n",
    "    \n",
    "    return out_img, ploty, left_fit, left_fitx, leftx_base, right_fit, right_fitx, rightx_base\n",
    "\n",
    "def Lcurvature_radius(persp, left_fit):\n",
    "    y_eval = np.max(persp[0])\n",
    "    left_curverad = (((1 + (2*left_fit[0]*y_eval*ym_per_pix + left_fit[1])**2)**1.5) / np.absolute(2*left_fit[0]))\n",
    "    Lcurvature_string = 'Left Curvature: {:.2f}Km'.format(left_curverad)\n",
    "    return Lcurvature_string\n",
    "\n",
    "def Rcurvature_radius(persp, right_fit):\n",
    "    y_eval = np.max(persp[0])\n",
    "    right_curverad = (((1 + (2*right_fit[0]*y_eval*ym_per_pix + right_fit[1])**2)**1.5) / np.absolute(2*right_fit[0])\n",
    "    Rcurvature_string = 'Right Curvature: {:.2f}m'.format(right_curverad)\n",
    "    return Rcurvature_string\n",
    "\n",
    "def pos_from_center(persp, leftx_base, rightx_base):\n",
    "    pos = persp.shape[1]\n",
    "    offset = (((leftx_base + rightx_base)/2.0-pos/2)*xm_per_pix)\n",
    "    location_string = 'Center offset: {:.2f}m'.format(offset)\n",
    "    return location_string\n",
    "\n",
    "def final_img(image, persp_transform_image, ploty, leftx_base, left_fit, left_fitx, rightx_base, right_fit, right_fitx, Minv):\n",
    "    #perspective transform back\n",
    "    warp_zero = np.zeros_like(persp_transform_image).astype(np.uint8)\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "    #Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0, 255, 0))\n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    newwarp = cv2.warpPerspective(color_warp, Minv, (persp_transform_image.shape[1], persp_transform_image.shape[0])) \n",
    "\n",
    "    #Combine the result with the original image\n",
    "    result = cv2.addWeighted(image, 1, newwarp, 0.3, 0)\n",
    "\n",
    "    #info strings\n",
    "    Rcurvature_string = Rcurvature_radius(persp_transform_image, right_fit)\n",
    "    Lcurvature_string = Lcurvature_radius(persp_transform_image, left_fit)\n",
    "    location_string = pos_from_center(persp_transform_image, leftx_base, rightx_base)\n",
    "\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    cv2.putText(result,Lcurvature_string,(100,50), font, 2,(255,255,255),2,cv2.LINE_AA)\n",
    "    cv2.putText(result,Rcurvature_string,(100,100), font, 2,(255,255,255),2,cv2.LINE_AA)\n",
    "    cv2.putText(result,location_string,(100,150), font, 2,(255,255,255),2,cv2.LINE_AA)\n",
    "    return result\n",
    "\n",
    "def process_frame(image):\n",
    "    #undistorting\n",
    "    undistorted_image = undistort(image)\n",
    "\n",
    "    #binary thresholding\n",
    "    hls_thresh_image = hls_thresh(undistorted_image, channel=hls_thresh_channel, thresh=hls_thresh_threshold)\n",
    "    abs_sobel_thresh_image = abs_sobel_thresh(undistorted_image, orient=abs_sobel_orient, sobel_kernel = abs_sobel_kernel, thresh= abs_sobel_threshold)\n",
    "    combined_image = combine_threshs(hls_thresh_image, abs_sobel_thresh_image)\n",
    "    windowed_image = filter(combined_image)\n",
    "\n",
    "    #perspective transform\n",
    "    persp_transform_image = transform_image(windowed_image, M, img_size)\n",
    "\n",
    "    #lanes\n",
    "    out_img, ploty, left_fit, left_fitx, leftx_base, right_fit, right_fitx, rightx_base = find_lanes(persp_transform_image)\n",
    "\n",
    "    #final image\n",
    "    result = final_img(image, persp_transform_image, ploty, leftx_base, left_fit, left_fitx, rightx_base, right_fit, right_fitx, Minv)\n",
    "    \n",
    "    #plotting\n",
    "    #plt.imshow(result)\n",
    "    #plt.savefig('test_image_8_annotated')\n",
    "\n",
    "    return result\n",
    "\n",
    "def make_video(input_path, output_path):\n",
    "    input_file = VideoFileClip(input_path)\n",
    "    output_clip = input_file.fl_image(process_frame)\n",
    "    output_clip.write_videofile(output_path, audio=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = read_images()\n",
    "\n",
    "#PARAMS\n",
    "img_size = (images[0].shape[1], images[0].shape[0])\n",
    "abs_sobel_orient = 'x'\n",
    "abs_sobel_kernel = 15\n",
    "abs_sobel_threshold = (24,100)\n",
    "mag_sobel_kernel = 15\n",
    "mag_sobel_threshold = (20,100)\n",
    "dir_sobel_kernel = 31\n",
    "dir_sobel_threshold = (0, np.pi/2)\n",
    "rgb_thresh_channel = 'r'\n",
    "rgb_thresh_threshold = (130,255)\n",
    "hls_thresh_channel = 's'\n",
    "hls_thresh_threshold = (110,255)\n",
    "hsv_thresh_channel = 'h'\n",
    "hsv_thresh_threshold = (0,110)\n",
    "YCrCb_thresh_channel = 'Y'\n",
    "YCrCb_thresh_threshold = (110,250)\n",
    "src = np.float32([(257, 685), (1050, 685), (583, 460),(702, 460)])\n",
    "dst = np.float32([(200, 720), (1080, 720), (200, 0), (1080, 0)])\n",
    "M = cv2.getPerspectiveTransform(src, dst) \n",
    "Minv = cv2.getPerspectiveTransform(dst, src)\n",
    "\n",
    "\n",
    "#IMAGE TRANSFORMATIONS\n",
    "undistorted_images = [undistort(image) for image in images]\n",
    "undistorted_drawn_images = [undistort_rect(undistorted_image) for undistorted_image in undistorted_images]\n",
    "abs_sobel_thresh_images = [abs_sobel_thresh(undistorted_image, orient=abs_sobel_orient, sobel_kernel = abs_sobel_kernel, thresh= abs_sobel_threshold) for undistorted_image in undistorted_images]\n",
    "mag_thresh_images = [mag_thresh(undistorted_image, sobel_kernel = mag_sobel_kernel, thresh= mag_sobel_threshold) for undistorted_image in undistorted_images]\n",
    "dir_thresh_images = [dir_thresh(undistorted_image, sobel_kernel = dir_sobel_kernel, thresh= dir_sobel_threshold) for undistorted_image in undistorted_images]\n",
    "rgb_thresh_images = [rgb_thresh(undistorted_image, channel=rgb_thresh_channel, thresh=rgb_thresh_threshold) for undistorted_image in undistorted_images]\n",
    "hls_thresh_images = [hls_thresh(undistorted_image, channel=hls_thresh_channel, thresh=hls_thresh_threshold) for undistorted_image in undistorted_images]\n",
    "hsv_thresh_images = [hsv_thresh(undistorted_image, channel=hsv_thresh_channel, thresh=hsv_thresh_threshold) for undistorted_image in undistorted_images]\n",
    "YCrCb_images = [YCrCb_thresh(undistorted_image, channel=YCrCb_thresh_channel, thresh=YCrCb_thresh_threshold) for undistorted_image in undistorted_images]\n",
    "combined_images = [combine_threshs(hls_thresh, abs_sobel_thresh) for hls_thresh, abs_sobel_thresh in zip(hls_thresh_images, abs_sobel_thresh_images)]\n",
    "windowed_images = [filter(combined) for combined in combined_images]\n",
    "birds_view_images = [transform_image(windowed_image, M, img_size) for windowed_image in windowed_images]\n",
    "histogram_images = [get_hist(birds_view_image) for birds_view_image in birds_view_images]\n",
    "progress = [images, undistorted_images, abs_sobel_thresh_images, mag_thresh_images, dir_thresh_images, rgb_thresh_images, hls_thresh_images, hsv_thresh_images, YCrCb_images]\n",
    "\n",
    "\n",
    "#PLOT CALIBRATION\n",
    "def plot_calibration():\n",
    "    distorted = images[1]\n",
    "    undistorted_drawn = undistorted_drawn_images[1]\n",
    "    labels = ['Distorted', 'Undistorted']\n",
    "    fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize = (15,4.5))\n",
    "    fig.tight_layout()\n",
    "    ax1.imshow(distorted)\n",
    "    ax1.set_title(labels[0])\n",
    "    ax1.axis('off')\n",
    "    ax2.imshow(undistorted_drawn)\n",
    "    ax2.set_title(labels[1])\n",
    "    ax2.axis('off')\n",
    "    plt.show()\n",
    "    plt.savefig('image.png', bbox_inches='tight', cmap='gray')\n",
    "print(\"Undistortion\")\n",
    "plot_calibration()\n",
    "\n",
    "\n",
    "#PLOT PROGRESS\n",
    "def plot_progress(progress, img):\n",
    "    labels = ['Original', 'Undistorted', 'Abs. Sobel Thresh.', 'Mag. Sobel Thresh.', 'Dir. Sobel Thresh.', 'RGB Thresh.', 'HLS Thresh.', 'HSV Thresh.', 'YCrCb Thresh']\n",
    "    fig, axes = plt.subplots(nrows=3, ncols=3, figsize = (15,10))\n",
    "    axes = axes.ravel()\n",
    "    fig.tight_layout()\n",
    "\n",
    "    for ax, transformation, label in zip(axes, progress, labels):\n",
    "        ax.imshow(transformation[img], cmap='gray')\n",
    "        ax.set_title(label)\n",
    "        ax.axis('off')\n",
    "    plt.show()\n",
    "    plt.savefig('image.png', bbox_inches='tight', cmap='gray')\n",
    "print(\"==== Binary threshold images ====\")\n",
    "plot_progress(progress, 2)\n",
    "\n",
    "\n",
    "#PLOT ALL\n",
    "def plot_all(images = [], birds_view_images = [], option = 'transformation'):\n",
    "    labels = [\"Yellow and white\", \"Yellow and white curved\", \"Poor lighting\", \"Straight white\", \"Yellow and white curved 2\", \"Very poor lighting 1\", \"Very poor lighting 2\", \"Very poor lighting 3\"]\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize = (10,3))\n",
    "    axes = axes.ravel()\n",
    "    fig.tight_layout()\n",
    "\n",
    "    if option == 'transformation':\n",
    "        for ax, image, label in zip(axes, images[1:3], labels[1:3]):\n",
    "            ax.imshow(image, cmap='gray')\n",
    "            ax.set_title(label)\n",
    "            ax.axis('off')\n",
    "\n",
    "    if option == 'histogram':\n",
    "        for ax, image, label in zip(axes, images[1:3], labels[1:3]):\n",
    "            ax.plot(image)\n",
    "            ax.set_title(label)\n",
    "\n",
    "    elif option == 'lanes':\n",
    "        for ax, birds_view_image, label in zip(axes, birds_view_images[1:3], labels[1:3]):\n",
    "            out_img, ploty, left_fit, left_fitx, leftx_base, right_fit, right_fitx, rightx_base = find_lanes(birds_view_image)\n",
    "            ax.imshow(out_img)\n",
    "            ax.set_title(label)\n",
    "            ax.plot(left_fitx, ploty, color='yellow')\n",
    "            ax.plot(right_fitx, ploty, color='yellow')\n",
    "            ax.axis('off')\n",
    "\n",
    "    elif option == 'final':\n",
    "        for ax, image, birds_view_image,label in zip(axes, images, birds_view_images[1:3], labels[1:3]):\n",
    "            out_img, ploty, left_fit, left_fitx, leftx_base, right_fit, right_fitx, rightx_base = find_lanes(birds_view_image)\n",
    "            result = final_img(image, birds_view_image, ploty, leftx_base, left_fit, left_fitx, rightx_base, right_fit, right_fitx, Minv)\n",
    "            ax.imshow(result)\n",
    "            ax.set_title(label)\n",
    "            ax.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "plot_all(images = histogram_images, option = 'histogram') #plot transformations\n",
    "#plot_all(images = images, birds_view_images = birds_view_images, option = 'transformation') #plot lane lines images\n",
    "plot_all(images = images, birds_view_images = birds_view_images, option = 'lanes') #plot lane lines images\n",
    "plot_all(images = images, birds_view_images = birds_view_images, option = 'final') #plot final images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PARAMS\n",
    "img_size = (images[0].shape[1], images[0].shape[0])\n",
    "abs_sobel_orient = 'x'\n",
    "abs_sobel_kernel = 15\n",
    "abs_sobel_threshold = (24,100)\n",
    "mag_sobel_kernel = 15\n",
    "mag_sobel_threshold = (20,100)\n",
    "dir_sobel_kernel = 31\n",
    "dir_sobel_threshold = (0, np.pi/2)\n",
    "rgb_thresh_channel = 'r'\n",
    "rgb_thresh_threshold = (130,255)\n",
    "hls_thresh_channel = 's'\n",
    "hls_thresh_threshold = (110,255)\n",
    "hsv_thresh_channel = 'h'\n",
    "hsv_thresh_threshold = (0,110)\n",
    "YCrCb_thresh_channel = 'Y'\n",
    "YCrCb_thresh_threshold = (110,250)\n",
    "src = np.float32([(257, 685), (1050, 685), (583, 460),(702, 460)])\n",
    "dst = np.float32([(200, 720), (1080, 720), (200, 0), (1080, 0)])\n",
    "M = cv2.getPerspectiveTransform(src, dst) \n",
    "Minv = cv2.getPerspectiveTransform(dst, src)\n",
    "\n",
    "nx, ny = 9, 6\n",
    "channels = 3\n",
    "\n",
    "#calibration image list\n",
    "image_names = glob.glob('./camera_cal/calibration*.jpg')\n",
    "\n",
    "#imgpoints and objpoints\n",
    "imgpoints = [] #2D in image plane\n",
    "objpoints = [] #3D in real life, all same\n",
    "objp = np.zeros((ny * nx, channels), np.float32)\n",
    "objp[:, :2] = np.mgrid[0:nx, 0:ny].T.reshape(-1, 2) #x, y coordinates\n",
    "\n",
    "\n",
    "#loop through\n",
    "for idx, image_name in enumerate(image_names):\n",
    "    cal_img = mpimg.imread(image_name)\n",
    "    cal_img_gray = cv2.cvtColor(cal_img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    #get corners\n",
    "    ret, corners = cv2.findChessboardCorners(cal_img_gray, (nx, ny), None)\n",
    "\n",
    "    #add to object and image points\n",
    "    if ret == True:\n",
    "        print(\"Corners for img\", str(idx))\n",
    "        imgpoints.append(corners)\n",
    "        objpoints.append(objp)\n",
    "\n",
    "        #draw and display corners\n",
    "        cv2.drawChessboardCorners(cal_img, (nx, ny), corners, ret)\n",
    "        write_path = \"./camera_cal_corners/calibration\" + str(idx) + \"_corners.jpg\"\n",
    "        cv2.imwrite(write_path, cal_img)\n",
    "        #print(\"Saved corners for image \", str(idx))\n",
    "\n",
    "\n",
    "#load arbitrary image for size\n",
    "img  = cv2.imread('./camera_cal/calibration11.jpg')\n",
    "img_size = (img.shape[1], img.shape[0])\n",
    "\n",
    "#camera calibration coefficients\n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img_size, None, None)\n",
    "\n",
    "#save camera calibration results for later\n",
    "calibration = {}\n",
    "calibration['mtx'] = mtx\n",
    "calibration['dist'] = dist\n",
    "pickle.dump(calibration, open(\"./calibration.p\", \"wb\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_video('project_video.mp4', 'project_video_OUTPUT.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "HTML(\"\"\"\n",
    "<video width=\"640\" height=\"360\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format('project_video_OUTPUT.mp4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
